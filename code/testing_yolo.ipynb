{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection import detect_grid_and_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = r\"C:\\Users\\77019\\Desktop\\kbtu\\5 sem\\tic_tac_toe_cv\\runs\\detect\\train3\\weights\\best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'x', 'confidence': 0.9677661061286926, 'cell_index': 8, 'bbox': (653, 825, 866, 1040)}\n",
      "{'label': 'x', 'confidence': 0.9607987403869629, 'cell_index': 2, 'bbox': (690, 279, 904, 497)}\n",
      "{'label': 'x', 'confidence': 0.9318078756332397, 'cell_index': 5, 'bbox': (679, 576, 892, 795)}\n",
      "{'label': 'x', 'confidence': 0.9250353574752808, 'cell_index': 1, 'bbox': (393, 274, 600, 485)}\n",
      "{'label': 'o', 'confidence': 0.9002107977867126, 'cell_index': 3, 'bbox': (108, 524, 336, 752)}\n",
      "{'label': 'o', 'confidence': 0.8587320446968079, 'cell_index': 7, 'bbox': (360, 836, 587, 1067)}\n",
      "{'label': 'o', 'confidence': 0.8538824915885925, 'cell_index': 6, 'bbox': (86, 824, 318, 1055)}\n",
      "{'label': 'o', 'confidence': 0.8463367223739624, 'cell_index': 4, 'bbox': (356, 546, 577, 769)}\n",
      "{'label': 'o', 'confidence': 0.7399865388870239, 'cell_index': 0, 'bbox': (118, 280, 345, 506)}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from detection import *  # Import helper functions from your file\n",
    "\n",
    "# Load YOLO model\n",
    "def load_yolo_model(model_path):\n",
    "    return YOLO(model_path)\n",
    "\n",
    "def get_original_image_cells(image_path, resize_dim=(600, 600), show_image=False):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Detect the grid and get the perspective transformation matrix\n",
    "    cells = detect_grid_and_cells(image_path, resize_dim=resize_dim, show_image=show_image)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    contours, _ = cv2.findContours(cv2.adaptiveThreshold(gray, 255, 1, 1, 11, 2), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_area, best_cnt = 0, None\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > 10000 and area > max_area:\n",
    "            max_area = area\n",
    "            best_cnt = c\n",
    "\n",
    "    # Find four corners of the grid for transformation\n",
    "    epsilon = 0.02 * cv2.arcLength(best_cnt, True)\n",
    "    approx = cv2.approxPolyDP(best_cnt, epsilon, True)\n",
    "    pts = np.array([point[0] for point in approx], dtype=\"float32\")\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s, diff = pts.sum(axis=1), np.diff(pts, axis=1)\n",
    "    rect[0], rect[2] = pts[np.argmin(s)], pts[np.argmax(s)]\n",
    "    rect[1], rect[3] = pts[np.argmin(diff)], pts[np.argmax(diff)]\n",
    "    \n",
    "    # Compute perspective transform and inverse transform matrices\n",
    "    dst_pts = np.array([[0, 0], [resize_dim[0], 0], [resize_dim[0], resize_dim[1]], [0, resize_dim[1]]], dtype=\"float32\")\n",
    "    M = cv2.getPerspectiveTransform(rect, dst_pts)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst_pts, rect)\n",
    "\n",
    "    # Apply perspective transform to get cells in transformed space\n",
    "    warped_image = apply_perspective_transform(image, rect, resize_dim[0], resize_dim[1])\n",
    "    transformed_cells = divide_into_cells((0, 0, resize_dim[0], resize_dim[1]), warped_image)\n",
    "\n",
    "    # Transform cells back to original coordinates using M_inv\n",
    "    original_cells = []\n",
    "    for cell in transformed_cells:\n",
    "        top_left = np.dot(M_inv, np.array([cell['x0'], cell['y0'], 1]))\n",
    "        bottom_right = np.dot(M_inv, np.array([cell['x1'], cell['y1'], 1]))\n",
    "        original_cells.append({\n",
    "            'x0': int(top_left[0] / top_left[2]),\n",
    "            'y0': int(top_left[1] / top_left[2]),\n",
    "            'x1': int(bottom_right[0] / bottom_right[2]),\n",
    "            'y1': int(bottom_right[1] / bottom_right[2])\n",
    "        })\n",
    "\n",
    "    return original_cells\n",
    "\n",
    "# Function to detect X/O and identify corresponding cell\n",
    "def detect_xo_and_identify_cells(frame, model, cells):\n",
    "    results = model.predict(source=frame, conf=0.5, show=False, verbose=False)  # Adjust `conf` if necessary\n",
    "    detected_objects = []\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            label = result.names[int(box.cls)]\n",
    "            confidence = float(box.conf)\n",
    "\n",
    "            # Determine the cell that contains this object\n",
    "            cell_index = find_cell_for_object((center_x, center_y), cells)\n",
    "            \n",
    "            if cell_index is not None:\n",
    "                detected_objects.append({\n",
    "                    'label': label,\n",
    "                    'confidence': confidence,\n",
    "                    'cell_index': cell_index,\n",
    "                    'bbox': (x1, y1, x2, y2)\n",
    "                })\n",
    "    return detected_objects\n",
    "\n",
    "# Helper function to find cell containing the center of the bounding box\n",
    "def find_cell_for_object(center, cells):\n",
    "    for index, cell in enumerate(cells):\n",
    "        if cell['x0'] <= center[0] <= cell['x1'] and cell['y0'] <= center[1] <= cell['y1']:\n",
    "            return index  # Return the cell index if the center is within cell bounds\n",
    "    return None\n",
    "\n",
    "# Function to annotate and display the results on the image\n",
    "def annotate_and_display(image, detected_objects, original_cells, scale_factor=0.5, show_image=True):\n",
    "    # Draw cell borders on the original image\n",
    "    for cell in original_cells:\n",
    "        x0, y0, x1, y1 = cell['x0'], cell['y0'], cell['x1'], cell['y1']\n",
    "        cv2.rectangle(image, (x0, y0), (x1, y1), (255, 255, 255), 2)  # White border for cells\n",
    "\n",
    "    # Annotate detected objects\n",
    "    for obj in detected_objects:\n",
    "        x1, y1, x2, y2 = obj['bbox']\n",
    "        label = obj['label']\n",
    "        cell_index = obj['cell_index']\n",
    "        confidence = obj['confidence']\n",
    "        \n",
    "        # Draw bounding box and label on the image\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f\"{label} ({cell_index})\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        # print(f\"Detected {label} in cell {cell_index} with confidence {confidence:.2f}\")\n",
    "\n",
    "    # Resize the image for display\n",
    "    resized_image = cv2.resize(image, (int(image.shape[1] * scale_factor), int(image.shape[0] * scale_factor)))\n",
    "\n",
    "    # Display the image with cells and detections if show_image is True\n",
    "    if show_image:\n",
    "        cv2.imshow(\"Tic Tac Toe Detection with Cells\", resized_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify get_original_image_cells to accept an image array instead of path\n",
    "def get_original_image_cells(image, resize_dim=(600, 600), show_image=False):\n",
    "    \"\"\"\n",
    "    Detect grid and cells in an image (either as a path or image array) and return cell coordinates.\n",
    "    \"\"\"\n",
    "    # Detect the grid and get the perspective transformation matrix\n",
    "    cells = detect_grid_and_cells(image_path=None, image=image, resize_dim=resize_dim, show_image=show_image)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    contours, _ = cv2.findContours(cv2.adaptiveThreshold(gray, 255, 1, 1, 11, 2), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_area, best_cnt = 0, None\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > 10000 and area > max_area:\n",
    "            max_area = area\n",
    "            best_cnt = c\n",
    "\n",
    "    # Find four corners of the grid for transformation\n",
    "    epsilon = 0.02 * cv2.arcLength(best_cnt, True)\n",
    "    approx = cv2.approxPolyDP(best_cnt, epsilon, True)\n",
    "    pts = np.array([point[0] for point in approx], dtype=\"float32\")\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s, diff = pts.sum(axis=1), np.diff(pts, axis=1)\n",
    "    rect[0], rect[2] = pts[np.argmin(s)], pts[np.argmax(s)]\n",
    "    rect[1], rect[3] = pts[np.argmin(diff)], pts[np.argmax(diff)]\n",
    "    \n",
    "    # Compute perspective transform and inverse transform matrices\n",
    "    dst_pts = np.array([[0, 0], [resize_dim[0], 0], [resize_dim[0], resize_dim[1]], [0, resize_dim[1]]], dtype=\"float32\")\n",
    "    M = cv2.getPerspectiveTransform(rect, dst_pts)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst_pts, rect)\n",
    "\n",
    "    # Apply perspective transform to get cells in transformed space\n",
    "    warped_image = apply_perspective_transform(image, rect, resize_dim[0], resize_dim[1])\n",
    "    transformed_cells = divide_into_cells((0, 0, resize_dim[0], resize_dim[1]), warped_image)\n",
    "\n",
    "    # Transform cells back to original coordinates using M_inv\n",
    "    original_cells = []\n",
    "    for cell in transformed_cells:\n",
    "        top_left = np.dot(M_inv, np.array([cell['x0'], cell['y0'], 1]))\n",
    "        bottom_right = np.dot(M_inv, np.array([cell['x1'], cell['y1'], 1]))\n",
    "        original_cells.append({\n",
    "            'x0': int(top_left[0] / top_left[2]),\n",
    "            'y0': int(top_left[1] / top_left[2]),\n",
    "            'x1': int(bottom_right[0] / bottom_right[2]),\n",
    "            'y1': int(bottom_right[1] / bottom_right[2])\n",
    "        })\n",
    "\n",
    "    return original_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No grid detected\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\shapedescr.cpp:280: error: (-215:Assertion failed) count >= 0 && (depth == CV_32F || depth == CV_32S) in function 'cv::arcLength'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 97\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m board \n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m \u001b[43mprocess_live_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 42\u001b[0m, in \u001b[0;36mprocess_live_video\u001b[1;34m(model_path, show_image, initial_positions)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError reading video.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m original_cells \u001b[38;5;241m=\u001b[39m \u001b[43mget_original_image_cells\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Initialize stable positions with the first frame detections\u001b[39;00m\n\u001b[0;32m     45\u001b[0m initial_detections \u001b[38;5;241m=\u001b[39m detect_xo_and_identify_cells(first_frame, model, original_cells)\n",
      "Cell \u001b[1;32mIn[16], line 77\u001b[0m, in \u001b[0;36mget_original_image_cells\u001b[1;34m(image, resize_dim, show_image)\u001b[0m\n\u001b[0;32m     74\u001b[0m         best_cnt \u001b[38;5;241m=\u001b[39m c\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Find four corners of the grid for transformation\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.02\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marcLength\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_cnt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m approx \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mapproxPolyDP(best_cnt, epsilon, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     79\u001b[0m pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([point[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m approx], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\shapedescr.cpp:280: error: (-215:Assertion failed) count >= 0 && (depth == CV_32F || depth == CV_32S) in function 'cv::arcLength'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from detection import *  # Import helper functions from your file\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "# Load YOLO model\n",
    "def load_yolo_model(model_path):\n",
    "    return YOLO(model_path)\n",
    "\n",
    "# Track the position stability for detected objects\n",
    "def track_positions(detected_objects, frame_time, stable_positions, duration=2):\n",
    "    confirmed_moves = []\n",
    "    for obj in detected_objects:\n",
    "        cell_index = obj['cell_index']\n",
    "        label = obj['label']\n",
    "        \n",
    "        if (label, cell_index) in stable_positions:\n",
    "            last_seen_time = stable_positions[(label, cell_index)]\n",
    "            if frame_time - last_seen_time >= duration:\n",
    "                confirmed_moves.append(obj)\n",
    "        else:\n",
    "            stable_positions[(label, cell_index)] = frame_time\n",
    "    \n",
    "    # Remove entries not seen in this frame\n",
    "    stable_positions = {key: stable_positions[key] for key in stable_positions if key in {(obj['label'], obj['cell_index']) for obj in detected_objects}}\n",
    "    return confirmed_moves, stable_positions\n",
    "\n",
    "# Process live video feed and detect objects\n",
    "def process_live_video(model_path, show_image=False):\n",
    "    model = load_yolo_model(model_path)\n",
    "\n",
    "    # Open live video feed (0 is usually the default webcam)\n",
    "    video = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Get grid cells from the first frame for reference\n",
    "    ret, first_frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading video.\")\n",
    "        return\n",
    "    original_cells = get_original_image_cells(first_frame, show_image=show_image)\n",
    "\n",
    "    # Initialize stable positions with the first frame detections\n",
    "    initial_detections = detect_xo_and_identify_cells(first_frame, model, original_cells)\n",
    "    frame_time = time.time()\n",
    "    current_positions = {(obj['label'], obj['cell_index']): frame_time for obj in initial_detections}\n",
    "\n",
    "    # Loop over frames\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_time = time.time()  # Current frame time\n",
    "        \n",
    "        detected_objects = detect_xo_and_identify_cells(frame, model, original_cells)\n",
    "        confirmed_moves, current_positions = track_positions(\n",
    "            detected_objects, \n",
    "            frame_time, \n",
    "            stable_positions=current_positions, \n",
    "            duration=2\n",
    "        )\n",
    "        \n",
    "        if confirmed_moves:\n",
    "            board = update_board(initial_state(), confirmed_moves)\n",
    "            # Display the updated board and moves if needed\n",
    "            print(\"Board updated:\", board)\n",
    "            \n",
    "            # TODO Here we call Gholibs function to get next move. This will take some time. \n",
    "            # send_move_to_robot(next_move) пока не надо\n",
    "            # wait for confirmation from robot пока не надо\n",
    "            # TODO update board according to the move\n",
    "            # TODO update current_positions according to the move\n",
    "            # frame_time = time.time()\n",
    "            # current_positions[next_move['label'], next_move['cell_index']] = frame_time\n",
    "\n",
    "        if show_image:\n",
    "            cv2.imshow('Real-Time Tic Tac Toe', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break  # Press 'q' to exit the loop\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "X = \"X\"\n",
    "O = \"O\"\n",
    "EMPTY = None\n",
    "\n",
    "def initial_state():\n",
    "    \"\"\" Returns starting state of the board. \"\"\"\n",
    "    return [[EMPTY, EMPTY, EMPTY],\n",
    "            [EMPTY, EMPTY, EMPTY]]\n",
    "\n",
    "def update_board(board, confirmed_moves):\n",
    "    for move in confirmed_moves:\n",
    "        row, col = move['cell_index'] // 3, move['cell_index'] % 3\n",
    "        board[row][col] = X if move['label'] == \"x\" else O\n",
    "    return board \n",
    "\n",
    "# Example usage\n",
    "process_live_video(MODEL_PATH, show_image=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
